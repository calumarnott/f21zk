epoch,train_loss,val_loss
0,27.935569,27.766301
1,27.204077,26.728801
2,25.441962,23.867042
3,20.822886,17.163891
4,12.413111,7.719644
5,4.514047,2.530810
6,1.778110,1.858884
7,1.468269,1.665901
8,1.312187,1.502953
9,1.191703,1.405487
10,1.082876,1.269897
11,0.983636,1.153886
12,0.896814,1.065437
13,0.811159,0.963634
14,0.733226,0.892157
15,0.661576,0.814268
16,0.606845,0.771383
17,0.543360,0.686095
18,0.488042,0.623436
19,0.437115,0.563241
20,0.391933,0.516678
21,0.351394,0.465094
22,0.313048,0.421491
23,0.278590,0.385341
24,0.251792,0.339600
25,0.223567,0.307506
26,0.201157,0.277759
27,0.179273,0.251182
28,0.159589,0.222204
29,0.141253,0.204570
30,0.128533,0.175982
31,0.112315,0.155739
32,0.101718,0.138283
33,0.092047,0.128633
34,0.079631,0.110592
35,0.070644,0.091992
36,0.059250,0.071359
37,0.047624,0.061578
38,0.037526,0.046473
39,0.031360,0.036014
40,0.028454,0.032784
41,0.024181,0.030556
42,0.024206,0.025149
43,0.022114,0.024416
44,0.020998,0.029344
45,0.019941,0.023312
46,0.019150,0.019594
47,0.017935,0.022021
48,0.017992,0.023182
49,0.016254,0.019551
